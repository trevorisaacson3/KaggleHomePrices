---
title: "Kaggle proj"
author: "Hawas Alsadeed"
date: "02/03/2022"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(fastDummies)
library(pls)
library(caret)
```

These are the data sets from our Kaggle Challenge.

We have two data sets

1] Train set (From row #1 to row #1460)

2] Test set (From row #1461 to row #2919)

```{r}
# making a data frame of the Training Set
train_df = read.csv("train.csv")
test_df = read.csv("test.csv")
```

```{r}
dim(train_df)
# checking number of rows and vertical columns in train data frame
```

```{r}
dim(test_df)
# checking number of rows and vertical columns in test data frame
```

```{r}
all_data = bind_rows(train_df,test_df)
dim(all_data)
head(all_data)
```

Sales price column created in test df also has null values

```{r}
tail(all_data)
```

Already the data has Id as row index, so we just remove the first column

```{r}
all_data=all_data[,-1]
head(all_data)
dim(all_data)
```

We have,

1] 80 columns (including target ) after droping ID column

2] Mixture of Numerical and Categorical data

```{r}
#checking data type
str(all_data)
```

Checking for null values and replacing them with mode for categorical features and median for numerical features

```{r}
all_data_na=100*sapply(all_data, function(x) sum(is.na(x)) ) /nrow(all_data)
all_data_na = all_data_na[all_data_na != 0]
missing_data = as.data.frame(all_data_na)
colnames(missing_data)="Missing Ratio"
head(missing_data)
```

Started imputing nulls

For categorical varaible putting mode for missing value

and for numerical varibale putting median

PoolQC : data description says NA means "No Pool". That make sense, given the huge ratio of missing value (+99%) and majority of houses have no Pool at all in general.

```{r}
all_data=all_data%>%
  replace_na(list(PoolQC = "None",MiscFeature = "None" , Alley="None",
                  Fence = "None", FireplaceQu="None", LotFrontage=median(all_data$LotFrontage,na.rm = TRUE), GarageType="None", 
                  GarageFinish="None", GarageQual="None", GarageCond="None",
                  GarageYrBlt=0,GarageArea=0,GarageCars=0, BsmtFinSF1 =0,  BsmtFinSF2 =0,  BsmtUnfSF =0, TotalBsmtSF =0,  BsmtFullBath =0,  BsmtHalfBath =0,
 BsmtQual  ="None" ,  BsmtCond  ="None" ,  BsmtExposure  ="None" ,  BsmtFinType1  ="None" ,  BsmtFinType2  ="None" ,
 MasVnrType="None",MasVnrArea=0, MSZoning=names(table(all_data$MSZoning))[table(all_data$MSZoning)==max(table(all_data$MSZoning))][1],Functional="Typ", Electrical=names(table(all_data$Electrical))[table(all_data$Electrical)==max(table(all_data$Electrical))][1],KitchenQual="TA",Exterior1st=names(table(all_data$Exterior1st))[table(all_data$Exterior1st)==max(table(all_data$Exterior1st))][1],Exterior2nd=names(table(all_data$Exterior2nd))[table(all_data$Exterior2nd)==max(table(all_data$Exterior2nd))][1],SaleType=names(table(all_data$SaleType))[table(all_data$SaleType)==max(table(all_data$SaleType))][1],
 MSSubClass=median(all_data$MSSubClass)))
```

Utilities : For this categorical feature all records are "AllPub", except for one "NoSeWa" and 2 NA . Since the house with 'NoSewa' is in the training set, this feature won't help in predictive modelling. We can then safely remove it.

```{r}
all_data=all_data[,-which(colnames(all_data)=="Utilities")]
```

Lets check for remaining missing values

```{r}
all_data_na_1=100*sapply(all_data, function(x) sum(is.na(x)) ) /nrow(all_data)
all_data_na_1 = all_data_na_1[all_data_na_1 != 0]
missing_data_1 = as.data.frame(all_data_na_1)
colnames(missing_data_1)="Missing Ratio"
head(missing_data_1)
```

sale price will be dropped from training set and then we will have no null values

```{r}
head(all_data)
```

Separating categorical predictors for one hot encoding

For categorical features we will use one hot encoding Because most of categorical features have 3 to 5 types.

Changing object type data into category type. It will help in one hot endcoding

```{r}
all_data[sapply(all_data, is.character)] <- lapply(all_data[sapply(all_data, is.character)], as.factor)
sum(is.na(all_data))
```


One Hot Encoding is a process in the data processing that is applied to categorical data, to convert it into a binary vector representation for use in machine learning algorithms

```{r}
new_train_df = all_data[1:1460,]
new_test_df = all_data[1460:nrow(all_data),]
```

```{r}
dim(new_train_df)
sum(is.na(new_train_df))
str(new_train_df)
dim(new_test_df)
sum(is.na(new_test_df))
str(new_test_df)
```

Spliting the data frame into numerical and categorical predictors for feature engineering

```{r}
numerical_train = new_train_df[!sapply(new_train_df, is.factor)]
categorical_train = new_train_df[sapply(new_train_df, is.factor)]
head(categorical_train)
dim(categorical_train)
```

```{r}
head(numerical_train)
dim(numerical_train)
```

converting categorical features into binary for train set

```{r}
ohe_cat_train = dummy_cols(categorical_train,select_columns = colnames(categorical_train)
           ,remove_selected_columns = TRUE)
head(ohe_cat_train)
```

ohe_train_total is the training data where categorical predicators are in binary
this is final train data for Machine learning

```{r}
ohe_train_total = bind_cols(ohe_cat_train , numerical_train)

head(ohe_train_total)
```

NOw test data cetegorical predictors into binary

```{r}
numerical_test = new_test_df[!sapply(new_test_df, is.factor)]
categorical_test = new_test_df[sapply(new_test_df, is.factor)]
head(categorical_test)
dim(categorical_test)
```

```{r}
head(numerical_test)
dim(numerical_test)
numerical_test_mod=numerical_test[,-which(colnames(numerical_test)=="SalePrice")]
```

converting categorical features into binary for test set

```{r}
ohe_cat_test = dummy_cols(categorical_test,select_columns = colnames(categorical_test)
                           ,remove_selected_columns = TRUE)
head(ohe_cat_test)
```

ohe_test_total is the testing data where categorical predicators are in binary
this is final test data for Machine learning

```{r}
ohe_test_total = bind_cols(ohe_cat_test , numerical_test_mod)

head(ohe_test_total)
```

test set is ready

PCR model

Is PCA + regression

principle components analysis takes in the predictor data frame and compresses it. It is used to reduce the number of predictors.

We will train our PCR on training data now

Spliting the data into predictor dataframe which is X

and

Response variable which is y

```{r}
head(ohe_train_total)
dim(ohe_train_total)
```

Removing response variable

```{r}
X = ohe_train_total[,-which(colnames(numerical_test)=="SalePrice")]
dim(X)
```

Putting response variable in y

```{r}
dim(train_df)
```

```{r}
y = train_df[,"SalePrice"]
head(y)
#y is response varibale
```

Log tranformation of Response variable

```{r}
y_log = log(y)
head(y_log)
```

Train test split

```{r}
set.seed(1234)
n=nrow(X)
test_index=sample(1:n,floor(0.3*n))
#scaling the data
X_scaled=scale(X)
X_train=X_scaled[-test_index,]
X_test=X_scaled[test_index,]
y_train=y_log[-test_index]
y_test=y_log[test_index]
```

To perform PCR we perfoem regression on the principle components derived from PCA

Creating a Regression intance

```{r}
pcr_model <- pcr(y_train~X_train, validation = "CV")
summary(pcr_model)
```

From the cumulative variability we note 90% has been achieved for 43 components. For some components the values 1 are so rare the variability is very high divering to infinity.

So we have taken 45 components to predict

```{r}
# Plot the root mean squared error
validationplot(pcr_model)
# Plot the R2
validationplot(pcr_model, val.type = "R2")
```

Now we fit the observations to train data and obtain the RMSE as below:

```{r}
pcr_pred_train <- predict(pcr_model, X_train, ncomp = 45)
sqrt(mean((pcr_pred_train - y_train)^2))
```

So the RMSE for PCR for training dataset is 0.1241

Our regression model is now trained on our pca data

Test Set

we need to do the same procesure as above that is use standard scaler on test data then use PCA with n_components 45 then use regression

```{r}
pcr_pred_test <- predict(pcr_model, X_test, ncomp = 45)
sqrt(mean((pcr_pred_test - y_test)^2))
```

RMSE for unseen the test set is 0.1425.

## Partial least square regression

checking of n_components for PLS

```{r}
# Build the model on training set
set.seed(1234)
train_data<-as.data.frame(cbind(y_train,X_train))
head(train_data)
model <- train(
  y_train~.,data=train_data, method = "pls",
  trControl = trainControl("cv", number = 10),
  tuneLength = 100
  )
# Plot model RMSE vs different values of components
plot(model)
# Print the best tuning parameter ncomp that
# minimize the cross-validation error, RMSE
model$bestTune
```

```{r}
# Summarize the final model
summary(model$finalModel)
```

```{r}
# Make predictions
predictions_train <- model %>% predict(train_data)
# Model performance metrics
data.frame(
  RMSE = caret::RMSE(predictions_train, train_data$y_train),
  Rsquare = caret::R2(predictions_train, train_data$y_train)
)
```

RMSE with partial least squares regression on training set is 0.0596

Using PLS on test set (unseen data)

```{r}
test_data<-as.data.frame(cbind(y_test,X_test))
# Make predictions
predictions_test <- model %>% predict(test_data)
# Model performance metrics
data.frame(
  RMSE = caret::RMSE(predictions_test, test_data$y_test),
  Rsquare = caret::R2(predictions_test, test_data$y_test)
)
```

RMSE on test data set is 0.0944